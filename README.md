# Задача 2. TF-IDF Baseline

### Получились следующие метрики:

Recall@1: 0.363645 — в 36.36% случаев правильный документ находится на 1 месте выдачи (показатель хорошей способности выявления ключевых терминов, характерных для конкретных пар вопрос-ответ)

Recall@3: 0.546915 — чуть более, чем в половине случаев правильный ответ содержится в топ-3 результатах (хорошая ранжировка документов по релевантности)

Recall@10: 0.711628 — в 71% случаев документ содержится в топ-10 (эффективная фильтрация явно нерелевантных документов при большом размере выдачи)

MRR: 0.473967 — в среднем правильный ответ находится между 2 и 3 позициями (1/0.4739 = 2.11), достаточно хороший результат

### Ограничения текущего подхода:

- Возможные проблемы с памятью и производительностью:  
  sim_matrix = cosine_similarity(X_questions, X_docs) требует O(N*M) памяти (N - вопросы теста, M - документы теста -> ~80K * 80K)

- Проблемы TF-IDF:  
  возможны проблемы с учётом семантики (похожие запросы могут не иметь пересечений в терминах)  
  синонимы обрабатываются как разные термины  
  слабая адаптация к длинным текстам: длинные ответы получают зашумленные вектора
